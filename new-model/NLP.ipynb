{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from detect_outlier import *\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data_no_outlier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(label):\n",
    "    if label == 0:\n",
    "        return np.random.randint(300, 580)\n",
    "    if label == 1:\n",
    "        return np.random.randint(580, 670)\n",
    "    if label == 2:\n",
    "        return np.random.randint(670, 740)\n",
    "    if label == 3:\n",
    "        return np.random.randint(740, 800)\n",
    "    if label == 4:\n",
    "        return np.random.randint(800, 850)\n",
    "def labeling(scores):\n",
    "    label = []\n",
    "    for score in scores:\n",
    "        if  score < 580:\n",
    "            label.append(0)\n",
    "        elif score >=580 and score < 670:\n",
    "            label.append(1)\n",
    "        elif score >= 670 and score < 740:\n",
    "            label.append(2)\n",
    "        elif score >= 740 and score < 800:\n",
    "            label.append(3)\n",
    "        elif score >= 800:\n",
    "            label.append(4)\n",
    "    return np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized =df.drop(\"address\", axis= 1).drop(\"createdAt\", axis= 1).drop(\"zscore\", axis= 1)\n",
    "label_column = df['label']\n",
    "df_normalized = (df_normalized - df_normalized.min()) / (df_normalized.max() - df_normalized.min())\n",
    "df_normalized['label'] = label_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_normalized[\n",
    "    [\n",
    "        \"balanceInUSD\",\n",
    "        # \"borrowInUSD\",\n",
    "        # \"depositInUSD\",\n",
    "        \"averageTotalAsset\",\n",
    "        \"frequencyMountOfTransaction\",\n",
    "        \"borrow_per_balance\",\n",
    "        \"deposit_per_balance\",\n",
    "        \"borrow_per_deposit\",\n",
    "        \"totalValueOfLiquidation\",\n",
    "        \"numberOfLiquidation\",\n",
    "        \"frequencyOfTransaction\",\n",
    "        \"frequencyOfDappTransactions\",\n",
    "        \"numberOfInteractedDapps\",\n",
    "        \"typesOfInteractedDapps\",\n",
    "        \"numberOfReputableDapps\",\n",
    "        \"age\",\n",
    "    ]\n",
    "].values)\n",
    "y = df_normalized[\"label\"].values\n",
    "new_y = np.array([score(y[i]) for i in range(len(y))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, new_y_train, new_y_test, y_train, y_test  = train_test_split(\n",
    "            X, new_y, y, test_size=0.2, random_state=41\n",
    "        )\n",
    "# Chuẩn bị dữ liệu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(14,)),  # input_shape là (16,)\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2484/2484 [==============================] - 4s 1ms/step - loss: 42339.9844 - mae: 106.4495 - val_loss: 1669.3667 - val_mae: 30.2473\n",
      "Epoch 2/10\n",
      "2484/2484 [==============================] - 4s 2ms/step - loss: 1624.9037 - mae: 30.1310 - val_loss: 1639.6251 - val_mae: 30.0947\n",
      "Epoch 3/10\n",
      "2484/2484 [==============================] - 3s 1ms/step - loss: 1588.6006 - mae: 30.0048 - val_loss: 1599.8960 - val_mae: 29.9895\n",
      "Epoch 4/10\n",
      "2484/2484 [==============================] - 3s 1ms/step - loss: 1556.6572 - mae: 29.8500 - val_loss: 1569.1078 - val_mae: 29.7652\n",
      "Epoch 5/10\n",
      "2484/2484 [==============================] - 3s 1ms/step - loss: 1524.0271 - mae: 29.6846 - val_loss: 1539.9388 - val_mae: 29.6006\n",
      "Epoch 6/10\n",
      "2484/2484 [==============================] - 3s 1ms/step - loss: 1499.2026 - mae: 29.5380 - val_loss: 1544.1257 - val_mae: 30.0697\n",
      "Epoch 7/10\n",
      "2484/2484 [==============================] - 3s 1ms/step - loss: 1479.6759 - mae: 29.4165 - val_loss: 1495.6595 - val_mae: 29.3812\n",
      "Epoch 8/10\n",
      "2484/2484 [==============================] - 3s 1ms/step - loss: 1466.9216 - mae: 29.3393 - val_loss: 1480.6559 - val_mae: 29.3209\n",
      "Epoch 9/10\n",
      "2484/2484 [==============================] - 3s 1ms/step - loss: 1455.8615 - mae: 29.2618 - val_loss: 1474.8185 - val_mae: 29.2025\n",
      "Epoch 10/10\n",
      "2484/2484 [==============================] - 3s 1ms/step - loss: 1444.3545 - mae: 29.1786 - val_loss: 1476.4053 - val_mae: 29.4776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c53eb5b690>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.fit(X_train, new_y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.02416321e-06, 8.72215501e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "       5.00667484e-18, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.30911626e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777/777 [==============================] - 1s 996us/step\n",
      "Dự đoán: [[637.2034 ]\n",
      " [729.5453 ]\n",
      " [633.9678 ]\n",
      " ...\n",
      " [633.88293]\n",
      " [633.8444 ]\n",
      " [635.99146]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8878376746245823"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_new = np.expand_dims(X_test, axis=0)\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Dự đoán:\", predictions)\n",
    "accuracy_score(y_test, labeling(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
